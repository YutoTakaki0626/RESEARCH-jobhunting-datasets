{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_full_text</th>\n",
       "      <th>finlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1370151453805871104</td>\n",
       "      <td>„Åä„ÅØ„Çà„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô‚òÄ\\n\\n‰ºëËÅ∑382Êó•ÁõÆ„ÄÇÊò®Êó•„ÅØ„Åü„Åè„Åï„Çì„ÅÆ„É™„Éó„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åó„Åüüò≠‚ú®„Åì...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1396246713044652032</td>\n",
       "      <td>Â∞±Ê¥ªÁîü„ÅÆ„Åü„ÇÅ„ÅÆ„Ç∞„É´„Éº„Éó„Éá„Ç£„Çπ„Ç´„ÉÉ„Ç∑„Éß„É≥ÂØæÁ≠ñ„Åæ„Å®„ÇÅ(40176view)ÔΩú https://t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1397335585459560449</td>\n",
       "      <td>„ÄêÁôªÈå≤„Åó„Å¶„Åè„Åπ„ÅçÂ∞±Ê¥ª„Çµ„Ç§„Éà„Äë\\nÂ∞±ËÅ∑Ê¥ªÂãï„Å´„Åä„ÅÑ„Å¶„ÄÅÊÉÖÂ†±Èáè„ÅåÂ§ß„Åç„Å™Ê≠¶Âô®„Å´„Å™„Çä„Åæ„Åô„ÄÇ ‰ª•‰∏ã„ÅÆ„Çµ„Ç§...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1375959601900777474</td>\n",
       "      <td>[Â∞±Ê¥ª„ÅÆ„ÅäÊÇ©„Åø„ÇíË®òÂÖ•„Åó„Å¶„Å≠] #ÂÆáË≥Ä„Å™„Å§„Åø „Ç¢„Éä„Å´Â∞±Ê¥ªÁõ∏Ë´á„Åó„Çà„ÅÜÔºÅÊäΩÈÅ∏„Åß8ÂêçÊßò„Å´ÂÆáË≥Ä„Ç¢„Éä„Å∏„ÅÆ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1347685399552880641</td>\n",
       "      <td>ES„ÅØÂ∞±Ê¥ª„Å´„Åä„Åë„Çã„ÅÇ„Å™„Åü„ÅÆÂêçÂà∫‰ª£„Çè„Çä„ÅÆ„Çà„ÅÜ„Å™„ÇÇ„ÅÆ„ÄÅ\\nÈù¢Êé•„Åß„ÇÇ„Éô„Éº„Çπ„Å´„Å™„Çã„ÅÆ„ÅØES„ÄÅÁîò„ÅèË¶ã„Å¶...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                    tweet_full_text  \\\n",
       "0  1370151453805871104  „Åä„ÅØ„Çà„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô‚òÄ\\n\\n‰ºëËÅ∑382Êó•ÁõÆ„ÄÇÊò®Êó•„ÅØ„Åü„Åè„Åï„Çì„ÅÆ„É™„Éó„ÅÇ„Çä„Åå„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åó„Åüüò≠‚ú®„Åì...   \n",
       "1  1396246713044652032  Â∞±Ê¥ªÁîü„ÅÆ„Åü„ÇÅ„ÅÆ„Ç∞„É´„Éº„Éó„Éá„Ç£„Çπ„Ç´„ÉÉ„Ç∑„Éß„É≥ÂØæÁ≠ñ„Åæ„Å®„ÇÅ(40176view)ÔΩú https://t...   \n",
       "2  1397335585459560449  „ÄêÁôªÈå≤„Åó„Å¶„Åè„Åπ„ÅçÂ∞±Ê¥ª„Çµ„Ç§„Éà„Äë\\nÂ∞±ËÅ∑Ê¥ªÂãï„Å´„Åä„ÅÑ„Å¶„ÄÅÊÉÖÂ†±Èáè„ÅåÂ§ß„Åç„Å™Ê≠¶Âô®„Å´„Å™„Çä„Åæ„Åô„ÄÇ ‰ª•‰∏ã„ÅÆ„Çµ„Ç§...   \n",
       "3  1375959601900777474  [Â∞±Ê¥ª„ÅÆ„ÅäÊÇ©„Åø„ÇíË®òÂÖ•„Åó„Å¶„Å≠] #ÂÆáË≥Ä„Å™„Å§„Åø „Ç¢„Éä„Å´Â∞±Ê¥ªÁõ∏Ë´á„Åó„Çà„ÅÜÔºÅÊäΩÈÅ∏„Åß8ÂêçÊßò„Å´ÂÆáË≥Ä„Ç¢„Éä„Å∏„ÅÆ...   \n",
       "4  1347685399552880641  ES„ÅØÂ∞±Ê¥ª„Å´„Åä„Åë„Çã„ÅÇ„Å™„Åü„ÅÆÂêçÂà∫‰ª£„Çè„Çä„ÅÆ„Çà„ÅÜ„Å™„ÇÇ„ÅÆ„ÄÅ\\nÈù¢Êé•„Åß„ÇÇ„Éô„Éº„Çπ„Å´„Å™„Çã„ÅÆ„ÅØES„ÄÅÁîò„ÅèË¶ã„Å¶...   \n",
       "\n",
       "   finlabel  \n",
       "0         1  \n",
       "1         4  \n",
       "2         4  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "def dumpJoblib(fileName, obj):\n",
    "    with open(fileName, mode=\"wb\") as f:\n",
    "        joblib.dump(obj, f, compress=3)\n",
    "        \n",
    "def loadJoblib(fileName):\n",
    "    with open(fileName, mode=\"rb\") as f:\n",
    "        return joblib.load(f)\n",
    "    \n",
    "df = loadJoblib('../Data/contain.joblib')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df['tweet_id'])\n",
    "label = list(df['finlabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.5.0\n",
      "  Downloading transformers-4.5.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.1 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fugashi==1.1.0\n",
      "  Downloading fugashi-1.1.0-cp38-cp38-macosx_10_14_x86_64.whl (282 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 282 kB 41.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipadic==1.0.0\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13.4 MB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytorch-lightning==1.2.7\n",
      "  Downloading pytorch_lightning-1.2.7-py3-none-any.whl (830 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 830 kB 50.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 45.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-macosx_10_11_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.2 MB 46.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (1.19.2)\n",
      "Requirement already satisfied: requests in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (4.62.3)\n",
      "Requirement already satisfied: packaging in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (2020.10.15)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (5.3.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (0.18.2)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.8 MB 30.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
      "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 329 kB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch>=1.4\n",
      "  Downloading torch-1.10.0-cp38-none-macosx_10_9_x86_64.whl (147.1 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147.1 MB 5.5 kB/s eta 0:00:011    |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 104.5 MB 9.3 MB/s eta 0:00:05     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 124.8 MB 8.9 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=0.8.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (0.8.3)\n",
      "Requirement already satisfied: click in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n",
      "Requirement already satisfied: six in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (1.15.0)\n",
      "Requirement already satisfied: joblib in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (0.17.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (1.25.11)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers==4.5.0) (2.4.7)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 155 kB 19.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.0 MB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (50.3.1.post20201107)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.5 MB 31.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.5-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97 kB 16.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.35.1)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.41.1-cp38-cp38-macosx_10_10_x86_64.whl (3.9 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.9 MB 41.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781 kB 38.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126 kB 32.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.4->pytorch-lightning==1.2.7) (3.7.4.3)\n",
      "Collecting aiohttp; extra == \"http\"\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-macosx_10_9_x86_64.whl (574 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 574 kB 42.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 155 kB 40.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>='4.4'; python_version < \"3.10\" in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (2.0.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp38-cp38-macosx_10_9_x86_64.whl (121 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 121 kB 37.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (20.3.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp38-cp38-macosx_10_9_x86_64.whl (81 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81 kB 5.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp38-cp38-macosx_10_9_x86_64.whl (45 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77 kB 4.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146 kB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>='4.4'; python_version < \"3.10\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (3.4.0)\n",
      "Building wheels for collected packages: ipadic\n",
      "  Building wheel for ipadic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556722 sha256=ea64721d9d067b3d7808a6dbd5ea3594c863a56e28be75813cf146161326ed0d\n",
      "  Stored in directory: /Users/takakiyuuto/Library/Caches/pip/wheels/45/b7/f5/a21e68db846eedcd00d69e37d60bab3f68eb20b1d99cdff652\n",
      "Successfully built ipadic\n",
      "Installing collected packages: sacremoses, tokenizers, transformers, fugashi, ipadic, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, protobuf, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-data-server, markdown, grpcio, tensorboard-plugin-wit, absl-py, tensorboard, torch, torchmetrics, pytorch-lightning, multidict, yarl, frozenlist, aiosignal, async-timeout, aiohttp\n",
      "Successfully installed absl-py-1.0.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 cachetools-4.2.4 frozenlist-1.2.0 fugashi-1.1.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 grpcio-1.41.1 ipadic-1.0.0 markdown-3.3.5 multidict-5.2.0 oauthlib-3.1.1 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-1.2.7 requests-oauthlib-1.3.0 rsa-4.7.2 sacremoses-0.0.46 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tokenizers-0.10.3 torch-1.10.0 torchmetrics-0.6.0 transformers-4.5.0 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0 pytorch-lightning==1.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PY_classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-16d7a6209ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPY_classification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertForSequenceClassificationMultiLabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mMODEL_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cl-tohoku/bert-base-japanese-whole-word-masking'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PY_classification'"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from RESEARCH-jobhunting-datasetsPY_classification.multi_classification import BertForSequenceClassificationMultiLabel\n",
    "\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert_scml = BertForSequenceClassificationMultiLabel(\n",
    "    MODEL_NAME, num_labels=4\n",
    ") \n",
    "bert_scml = bert_scml.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for emotion in label:\n",
    "    if emotion == 63:\n",
    "        labels.append([1, 0, 0, 0])\n",
    "    elif emotion == 64:\n",
    "        labels.append([0, 1, 0, 0])\n",
    "    elif emotion == 65:\n",
    "        labels.append([0, 0, 1, 0])\n",
    "    else:\n",
    "        labels.append([0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 152\n",
    "dataset_for_loader = []\n",
    "\n",
    "for text, label in zip(data, labels):\n",
    "    encoding = tokenizer(\n",
    "      text, \n",
    "      max_length=max_length,\n",
    "      padding='max_length',\n",
    "      truncation=True\n",
    "    )\n",
    "    encoding['labels'] = label\n",
    "    encoding = {k: torch.tensor(v).to(device=device) for k, v in encoding.items() }\n",
    "    dataset_for_loader.append(encoding)\n",
    "    \n",
    "\n",
    "random.shuffle(dataset_for_loader)\n",
    "n = len(dataset_for_loader)\n",
    "n_train = int(0.6*n)\n",
    "n_val = int(0.2*n)\n",
    "dataset_train = dataset_for_loader[:n_train]\n",
    "dataset_val = dataset_for_loader[n_train:n_train+n_val]\n",
    "dataset_test = dataset_for_loader[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f83df769550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train, batch_size=16, shuffle=True\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val, batch_size=16\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test, batch_size=16\n",
    ")\n",
    "\n",
    "dataloader_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                    | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | bert_scml | BertForSequenceClassificationMultiLabel | 110 M \n",
      "----------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "442.482   Total estimated model params size (MB)\n",
      "/home/takakiyuto/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takakiyuto/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d7f2c33b4548f5b25236c53fdb2fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PY_classification.pytorch_lightning_multi import BertForSequenceClassificationMultiLabel_pl\n",
    "\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    save_weights_only=True,\n",
    "    dirpath='part/model/'\n",
    ")\n",
    "\n",
    "#Â≠¶ÁøíÊñπÊ≥ïÊåáÂÆö\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=10,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassificationMultiLabel_pl(\n",
    "    MODEL_NAME, num_labels=4, lr=1e-5\n",
    ")\n",
    "\n",
    "trainer.fit(model, dataloader_train, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data loss:0.2354281097650528\n",
      "The best path is /home/takakiyuto/Desktop/RESEARCH-COVID19-datasets/part/model/epoch=0-step=1406.ckpt\n"
     ]
    }
   ],
   "source": [
    "best_model_path = checkpoint.best_model_path\n",
    "print(f'validation data loss:{checkpoint.best_model_score}')\n",
    "print(f'The best path is {best_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2ab13a3d05730e62\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2ab13a3d05730e62\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/takakiyuto/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55669cf8681451eb7a342a8fc57872f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'accuracy': 0.789712131023407}\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.7897\n"
     ]
    }
   ],
   "source": [
    "test = trainer.test(test_dataloaders=dataloader_test, ckpt_path=best_model_path)\n",
    "print(f'Accuracy: {test[0][\"accuracy\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
