{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_full_text</th>\n",
       "      <th>finlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1370151453805871104</td>\n",
       "      <td>ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™â˜€\\n\\nä¼‘è·382æ—¥ç›®ã€‚æ˜¨æ—¥ã¯ãŸãã•ã‚“ã®ãƒªãƒ—ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸğŸ˜­âœ¨ã“...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1396246713044652032</td>\n",
       "      <td>å°±æ´»ç”Ÿã®ãŸã‚ã®ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³å¯¾ç­–ã¾ã¨ã‚(40176view)ï½œ https://t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1397335585459560449</td>\n",
       "      <td>ã€ç™»éŒ²ã—ã¦ãã¹ãå°±æ´»ã‚µã‚¤ãƒˆã€‘\\nå°±è·æ´»å‹•ã«ãŠã„ã¦ã€æƒ…å ±é‡ãŒå¤§ããªæ­¦å™¨ã«ãªã‚Šã¾ã™ã€‚ ä»¥ä¸‹ã®ã‚µã‚¤...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1375959601900777474</td>\n",
       "      <td>[å°±æ´»ã®ãŠæ‚©ã¿ã‚’è¨˜å…¥ã—ã¦ã­] #å®‡è³€ãªã¤ã¿ ã‚¢ãƒŠã«å°±æ´»ç›¸è«‡ã—ã‚ˆã†ï¼æŠ½é¸ã§8åæ§˜ã«å®‡è³€ã‚¢ãƒŠã¸ã®...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1347685399552880641</td>\n",
       "      <td>ESã¯å°±æ´»ã«ãŠã‘ã‚‹ã‚ãªãŸã®ååˆºä»£ã‚ã‚Šã®ã‚ˆã†ãªã‚‚ã®ã€\\né¢æ¥ã§ã‚‚ãƒ™ãƒ¼ã‚¹ã«ãªã‚‹ã®ã¯ESã€ç”˜ãè¦‹ã¦...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                    tweet_full_text  \\\n",
       "0  1370151453805871104  ãŠã¯ã‚ˆã†ã”ã–ã„ã¾ã™â˜€\\n\\nä¼‘è·382æ—¥ç›®ã€‚æ˜¨æ—¥ã¯ãŸãã•ã‚“ã®ãƒªãƒ—ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸğŸ˜­âœ¨ã“...   \n",
       "1  1396246713044652032  å°±æ´»ç”Ÿã®ãŸã‚ã®ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³å¯¾ç­–ã¾ã¨ã‚(40176view)ï½œ https://t...   \n",
       "2  1397335585459560449  ã€ç™»éŒ²ã—ã¦ãã¹ãå°±æ´»ã‚µã‚¤ãƒˆã€‘\\nå°±è·æ´»å‹•ã«ãŠã„ã¦ã€æƒ…å ±é‡ãŒå¤§ããªæ­¦å™¨ã«ãªã‚Šã¾ã™ã€‚ ä»¥ä¸‹ã®ã‚µã‚¤...   \n",
       "3  1375959601900777474  [å°±æ´»ã®ãŠæ‚©ã¿ã‚’è¨˜å…¥ã—ã¦ã­] #å®‡è³€ãªã¤ã¿ ã‚¢ãƒŠã«å°±æ´»ç›¸è«‡ã—ã‚ˆã†ï¼æŠ½é¸ã§8åæ§˜ã«å®‡è³€ã‚¢ãƒŠã¸ã®...   \n",
       "4  1347685399552880641  ESã¯å°±æ´»ã«ãŠã‘ã‚‹ã‚ãªãŸã®ååˆºä»£ã‚ã‚Šã®ã‚ˆã†ãªã‚‚ã®ã€\\né¢æ¥ã§ã‚‚ãƒ™ãƒ¼ã‚¹ã«ãªã‚‹ã®ã¯ESã€ç”˜ãè¦‹ã¦...   \n",
       "\n",
       "   finlabel  \n",
       "0         1  \n",
       "1         4  \n",
       "2         4  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "def dumpJoblib(fileName, obj):\n",
    "    with open(fileName, mode=\"wb\") as f:\n",
    "        joblib.dump(obj, f, compress=3)\n",
    "        \n",
    "def loadJoblib(fileName):\n",
    "    with open(fileName, mode=\"rb\") as f:\n",
    "        return joblib.load(f)\n",
    "    \n",
    "df = loadJoblib('Data/contain.joblib')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df['tweet_full_text'])\n",
    "label = list(df['finlabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.5.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (4.5.0)\n",
      "Requirement already satisfied: fugashi==1.1.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: ipadic==1.0.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: pytorch-lightning==1.2.7 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (1.2.7)\n",
      "Requirement already satisfied: requests in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (2.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (2020.10.15)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (0.0.46)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (1.19.2)\n",
      "Requirement already satisfied: packaging in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (20.4)\n",
      "Requirement already satisfied: filelock in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from transformers==4.5.0) (4.62.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (0.18.2)\n",
      "Requirement already satisfied: torch>=1.4 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (1.10.0)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (5.3.1)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (0.8.3)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (2.7.0)\n",
      "Requirement already satisfied: torchmetrics>=0.2.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from pytorch-lightning==1.2.7) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.0) (1.25.11)\n",
      "Requirement already satisfied: joblib in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (0.17.0)\n",
      "Requirement already satisfied: six in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (1.15.0)\n",
      "Requirement already satisfied: click in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers==4.5.0) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from torch>=1.4->pytorch-lightning==1.2.7) (3.7.4.3)\n",
      "Requirement already satisfied: aiohttp; extra == \"http\" in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (3.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (3.19.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (50.3.1.post20201107)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.35.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (3.3.5)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.41.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (20.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7) (1.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>='4.4'; python_version < \"3.10\" in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (2.0.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>='4.4'; python_version < \"3.10\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (3.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/takakiyuuto/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0 pytorch-lightning==1.2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from multi_classification import BertForSequenceClassificationMultiLabel\n",
    "\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccab1acb5174ed7b28f87435469c36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/258k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b440b360df9c40e3b864e9a1c2c2b2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/110 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b1c4937628403094a0dd5032c33e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/479 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeafbd0f8e5343c6804dd66bc5cef652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bebc4c71d084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m bert_scml = BertForSequenceClassificationMultiLabel(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ) \n\u001b[1;32m      5\u001b[0m \u001b[0mbert_scml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_scml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RESEARCH-jobhunting-datasets/multi_classification.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, num_labels)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     self.linear = torch.nn.Linear(\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                 \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                 resolved_archive_file = cached_path(\n\u001b[0m\u001b[1;32m   1031\u001b[0m                     \u001b[0marchive_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                     \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1426\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{url} not found in cache or force_download set to True, downloading to {temp_file.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m             \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"storing {url} in cache at {cache_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/tempfile.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0m_functools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;31m# Avoid closing the file as long as the wrapper is alive,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;31m# see issue #18879.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert_scml = BertForSequenceClassificationMultiLabel(\n",
    "    MODEL_NAME, num_labels=4\n",
    ") \n",
    "bert_scml = bert_scml.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for lbl in label:\n",
    "    if lbl == 1:\n",
    "        labels.append([1, 0, 0, 0, 0])\n",
    "    elif lbl == 2:\n",
    "        labels.append([0, 1, 0, 0, 0])\n",
    "    elif lbl == 3:\n",
    "        labels.append([0, 0, 1, 0, 0])\n",
    "    elif lbl == 4:\n",
    "        labels.append([0, 0, 0 ,1, 0])\n",
    "    else:\n",
    "        labels.append([0, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 155\n",
    "dataset_for_loader = []\n",
    "\n",
    "for text, label in zip(data, labels):\n",
    "    encoding = tokenizer(\n",
    "      text, \n",
    "      max_length=max_length,\n",
    "      padding='max_length',\n",
    "      truncation=True\n",
    "    )\n",
    "    encoding['labels'] = label\n",
    "    encoding = {k: torch.tensor(v).to(device=device) for k, v in encoding.items() }\n",
    "    dataset_for_loader.append(encoding)\n",
    "    \n",
    "\n",
    "random.shuffle(dataset_for_loader)\n",
    "n = len(dataset_for_loader)\n",
    "n_train = int(0.6*n)\n",
    "n_val = int(0.2*n)\n",
    "dataset_train = dataset_for_loader[:n_train]\n",
    "dataset_val = dataset_for_loader[n_train:n_train+n_val]\n",
    "dataset_test = dataset_for_loader[n_train+n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f83df769550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train, batch_size=16, shuffle=True\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val, batch_size=16\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test, batch_size=16\n",
    ")\n",
    "\n",
    "dataloader_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                                    | Params\n",
      "----------------------------------------------------------------------\n",
      "0 | bert_scml | BertForSequenceClassificationMultiLabel | 110 M \n",
      "----------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "442.482   Total estimated model params size (MB)\n",
      "/home/takakiyuto/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takakiyuto/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d7f2c33b4548f5b25236c53fdb2fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PY_classification.pytorch_lightning_multi import BertForSequenceClassificationMultiLabel_pl\n",
    "\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1,\n",
    "    save_weights_only=True,\n",
    "    dirpath='part/model/'\n",
    ")\n",
    "\n",
    "#å­¦ç¿’æ–¹æ³•æŒ‡å®š\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=10,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassificationMultiLabel_pl(\n",
    "    MODEL_NAME, num_labels=4, lr=1e-5\n",
    ")\n",
    "\n",
    "trainer.fit(model, dataloader_train, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data loss:0.2354281097650528\n",
      "The best path is /home/takakiyuto/Desktop/RESEARCH-COVID19-datasets/part/model/epoch=0-step=1406.ckpt\n"
     ]
    }
   ],
   "source": [
    "best_model_path = checkpoint.best_model_path\n",
    "print(f'validation data loss:{checkpoint.best_model_score}')\n",
    "print(f'The best path is {best_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2ab13a3d05730e62\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2ab13a3d05730e62\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/takakiyuto/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55669cf8681451eb7a342a8fc57872f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'accuracy': 0.789712131023407}\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy: 0.7897\n"
     ]
    }
   ],
   "source": [
    "test = trainer.test(test_dataloaders=dataloader_test, ckpt_path=best_model_path)\n",
    "print(f'Accuracy: {test[0][\"accuracy\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
